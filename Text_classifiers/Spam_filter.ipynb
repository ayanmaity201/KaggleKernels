{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam Classifier using Multinomial Naive Bayes from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I am going to develop a simple email or sms spam classifier using Multinomial Naive Bayes Algorithm written from scratch. For that purpose we first need to know basic algorithm behind naive bayes. \n",
    " Here I am using SMS dataset form UCI ,that contains almost 5500 examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_cell_guid": "baa7efe5-e9c8-4d9f-89ff-628c6f3254a7",
    "_uuid": "9469b51bf384dfec6aeafe5a5e06dd246627d368",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "_cell_guid": "73b99fcc-5a44-4357-9fd0-162498d96487",
    "_uuid": "938ec5f1cee4e936aacffb77a2d090a00f0329ae",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"spam.csv\",encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "_cell_guid": "b044150f-dc28-418a-82bf-8b645ad907b2",
    "_uuid": "62ae4664163b69ee441a3f44c9148ba7dc5c9f1f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will map the Y_label which is 'v1' column to {0,1}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "_cell_guid": "6e462686-2887-41e5-a68f-9eb3fc9de4e9",
    "_uuid": "6f28f3502f444616a7303b8ae1e1d4d0ce0bc8b4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   v1                                                 v2 Unnamed: 2  \\\n",
       "0   0  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   0                      Ok lar... Joking wif u oni...        NaN   \n",
       "2   1  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   0  U dun say so early hor... U c already then say...        NaN   \n",
       "4   0  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict = {'ham':0,'spam':1}\n",
    "df['v1'] = df['v1'].map(dict)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deleting unecessary columns from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "_cell_guid": "c329958b-62ff-4c8a-b0f2-e6df5e6bff72",
    "_uuid": "ff02846722dbb7413c42cf56e68d3bcbe280ba5d"
   },
   "outputs": [],
   "source": [
    "del df['Unnamed: 2']\n",
    "del df['Unnamed: 3']\n",
    "del df['Unnamed: 4']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now first we need to find a way to represent the text data to a numerical form.To do this I will be using CountVectorizer that creates a dictionary of all the words present in that corpus(i.e. the whole text document).Then we can transform the text data into a matrix form whose (i,j)th elemment is nothong but the number of times the jth word has appeared in the ith document or example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "_cell_guid": "461bdd06-4c0e-4e12-bb49-3e7c6ee5951f",
    "_uuid": "cc33f5651728aee96c2f5ee74270ff96793fd0c7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=1, max_df=1.0, max_features=None, min_df=1e-05,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "c_vec = CountVectorizer(lowercase=1,min_df=.00001,stop_words='english')\n",
    "c_vec.fit(df['v2'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spliting the dataframe into train and test dataframe ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "_cell_guid": "24135a8c-c851-46f8-a032-899c566c781f",
    "_uuid": "febde24e218c2edd19a20b66a94d3b143c9873f3",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = df[0:5000]\n",
    "test_df = df[5000:]\n",
    "test_df.index=(range(test_df.shape[0]))\n",
    "Y_train = train_df['v1'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "First method we have to write for naive bayes is for calculating probability of spam and ham class.We just have to find how many spam sms and ham sms is there in data and then divide it by total number of examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "_cell_guid": "3d0cb919-5d54-4442-868b-4fee0a53839d",
    "_uuid": "6aeb0de33b363845f6b1cebff34a00391faf6067",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prob_y(Y_train,num_class=2):\n",
    "    p_y = np.zeros([num_class,])\n",
    "    n_y = np.zeros([num_class,])\n",
    "    d_y = Y_train.shape[0]\n",
    "    for i in range(Y_train.shape[0]):\n",
    "        n_y[Y_train[i]] = n_y[Y_train[i]]+1\n",
    "    p_y = n_y/d_y\n",
    "    return p_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "_cell_guid": "b6a62bcf-92db-47af-9eef-b5fb2f1fcbee",
    "_uuid": "dcab2eb18bc8c2ae90aa0bb1e8f90e2b666ef8d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.8654,  0.1346])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_y = prob_y(Y_train)\n",
    "p_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The next method is prob_xy which is P(X|Y) . It is the probabilty of getting the word X in the class Y.This function produces a \n",
    "num_class * num_of_words matrix. First column of the matrix contains P(X|Y=0) and second column P(X|Y=1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "_cell_guid": "c9e8a8bb-9125-4621-9544-8aeb61f53515",
    "_uuid": "a5617f18d0c6aad5e13d65a34509633624078a40",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prob_xy(c_vec,train_df,Y_train,num_class=2):\n",
    "    d_y = np.zeros([num_class,])+len(c_vec.vocabulary_)\n",
    "    p_xy = np.zeros([num_class,len(c_vec.vocabulary_)])\n",
    "    for i in np.unique(Y_train):\n",
    "        temp_df = train_df[train_df['v1']==i]\n",
    "        temp_x = c_vec.transform(temp_df['v2'].values)\n",
    "        n_xy = np.sum(temp_x,axis=0)+1\n",
    "        d_y[i] = d_y[i]+np.sum(temp_x)\n",
    "        p_xy[i] = n_xy/d_y[i] \n",
    "    return p_xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "_cell_guid": "757899a6-f89a-414f-9579-02cc315a92d6",
    "_uuid": "4d812b0e950c5f19328007de29d269ad144cfddc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.57944697e-05,   2.57944697e-05,   5.15889393e-05, ...,\n",
       "          2.57944697e-05,   2.57944697e-04,   5.15889393e-05],\n",
       "       [  5.77064316e-04,   1.52135138e-03,   5.24603924e-05, ...,\n",
       "          1.04920785e-04,   5.24603924e-05,   5.24603924e-05]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_xy = prob_xy(c_vec,train_df,Y_train,2)\n",
    "p_xy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we come to final stage of this algorithm where we have to find P(Y|X) i.e. the probability of a document X to belong to class Y . From Bayes theorem in probability theory , P(Y|X) = P(X|Y) * P(Y)/P(X) . \n",
    "And then finally the class label Y for a document X will be accroding to  max(P(Y=0|X),P(Y=1|X))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "_cell_guid": "0c8781cf-1e29-4aef-867f-572eba454b9b",
    "_uuid": "e87a0b8bcb55d82917161002d9334b29e354b4a0",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify(c_vec,test_df,p_xy,p_y,num_class=2):\n",
    "    pred = []\n",
    "    pre_yx = []\n",
    "    for doc in test_df['v2'].values:\n",
    "        temp_doc = (c_vec.transform([doc])).todense()\n",
    "        temp_prob = np.zeros([num_class,])\n",
    "        for i in range(num_class):\n",
    "            temp_prob[i] = np.prod(np.power(p_xy[i],temp_doc))*p_y[i]\n",
    "        pred.append(np.argmax(temp_prob))\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "_cell_guid": "2ae99747-5f3e-47c1-bf98-175f517cc454",
    "_uuid": "166764833e0b74443c023dfbf8e70af64891ede9",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = classify(c_vec,test_df,p_xy,p_y,num_class=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our classification is done , we will find the accuracy for both the training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "_cell_guid": "0300db05-60ee-429b-bedf-f00773065227",
    "_uuid": "e02856808e7626322347e009cf8beffd096b814b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(pred,Y):\n",
    "    return np.sum(pred==Y)/Y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "_cell_guid": "8ea2bb09-b381-4dd1-a77c-054d75ccd820",
    "_uuid": "a4cb861cbb5cedc2d123cad0ff33f25b178aae9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data Accuaracy = 0.984265734266\n"
     ]
    }
   ],
   "source": [
    "Y_test = test_df['v1'].values\n",
    "test_accuracy = accuracy(pred,Y_test)\n",
    "print('Test Data Accuaracy = '+str(test_accuracy)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "_cell_guid": "a45b3161-d2c2-4a18-b7f3-1bdbca78adb5",
    "_uuid": "c25f7b9c380f75c13976b238d7b37d2029f44f49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Accuracy = 0.995\n"
     ]
    }
   ],
   "source": [
    "pred_train = classify(c_vec,train_df,p_xy,p_y,num_class=2)\n",
    "print('Train Data Accuracy = '+str(accuracy(pred_train,Y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f72ea332-6ede-48fd-bba5-dff9a0c47970",
    "_uuid": "2e93e1fcadefd94eb6e6adb5416feef429a7e513",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
